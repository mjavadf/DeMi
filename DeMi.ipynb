{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation\n",
    "This block is for preparing libraries and modules which will be used in the project. New libraries may be added during the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the following lines to install the required packages\n",
    "# !pip install pandas\n",
    "# !pip install matplotlib\n",
    "# !pip install seaborn\n",
    "# !pip install pycountry\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pycountry\n",
    "\n",
    "datasets_path = 'datasets/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questions\n",
    "\n",
    "## What are the main countries of origin of immigrants in Italy, and how have these trends changed over the past 5 years?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate mashed-up data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_iso3(code):\n",
    "    if pd.isna(code):  # Check if the value is NaN\n",
    "        return None  # Keep it as NaN\n",
    "    if code == \"UK\":  # Manually correct \"UK\" to \"GBR\"\n",
    "        return \"GBR\"\n",
    "    try:\n",
    "        return pycountry.countries.get(alpha_2=code).alpha_3\n",
    "    except AttributeError:\n",
    "        # print(f\"Warning: Country code '{code}' not found in ISO 3166-1 alpha-2!\")  # Debugging\n",
    "        return code  # Keep the original if not found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load datasets\n",
    "d4 = pd.read_csv(f'{datasets_path}IstatData/Immigrants - citizenship (IT1,28_185_DF_DCIS_MIGRAZIONI_2,1.0).csv')\n",
    "d5 = pd.read_csv(f'{datasets_path}IstatData/Type of residence permit and citizenship (IT1,29_348_DF_DCIS_PERMSOGG1_1,1.0).csv')\n",
    "d15 = pd.read_csv(f'{datasets_path}OECD/OECD.ELS.IMD,DSD_MIG@DF_MIG,1.0+ITA..A.B11.csv')\n",
    "\n",
    "Sex_dictionary = {\n",
    "  1: \"Male\",\n",
    "  2: \"Female\",\n",
    "  9: \"Total\",\n",
    "}\n",
    "\n",
    "Permit_Type_dictionary = {\n",
    "  \"LONGT\": \"Long-term\",\n",
    "  \"NLONGT\": \"Short-term\",\n",
    "  \"TOTAL\": \"Total\",\n",
    "}\n",
    "\n",
    "d4_filtered = d4[d4['AGE'] == 'TOTAL'][['CITIZENSHIP',\n",
    "                                        'SEX',\n",
    "                                        # 'AGE',\n",
    "                                        'TIME_PERIOD',\n",
    "                                        'OBS_VALUE']]\n",
    "d4_filtered = d4_filtered.rename(columns={'CITIZENSHIP': 'Country_Code',\n",
    "                                          'SEX': 'Sex',\n",
    "                                        #   'AGE': 'Age_range',\n",
    "                                          'TIME_PERIOD': 'Year',\n",
    "                                          'OBS_VALUE': 'Value'})\n",
    "d4_filtered = d4_filtered[d4_filtered['Country_Code'].str.len() == 2]\n",
    "# Convert country codes to ISO 3166-1 alpha-3\n",
    "d4_filtered['Country_Code'] = d4_filtered['Country_Code'].apply(convert_to_iso3)\n",
    "# Add column dataset = d4\n",
    "d4_filtered['Dataset'] = 'Immigrants - citizenship'\n",
    "d4_filtered['Dataset_Code'] = 'D4'\n",
    "\n",
    "\n",
    "d5_filtered = d5[['MOSTREL_CCITENSHIP',\n",
    "                  'SEX', 'TYPE_RES_PERMIT',\n",
    "                  'TIME_PERIOD',\n",
    "                  'OBS_VALUE']]\n",
    "d5_filtered = d5_filtered.rename(columns={'MOSTREL_CCITENSHIP': 'Country_Code',\n",
    "                                          'SEX': 'Sex',\n",
    "                                          'TYPE_RES_PERMIT': 'Permit_Type',\n",
    "                                          'TIME_PERIOD': 'Year',\n",
    "                                          'OBS_VALUE': 'Value'})\n",
    "d5_filtered = d5_filtered[d5_filtered['Country_Code'].str.len() == 2]\n",
    "# Convert country codes to ISO 3166-1 alpha-3\n",
    "d5_filtered['Country_Code'] = d5_filtered['Country_Code'].apply(convert_to_iso3)\n",
    "# Add column dataset = d5\n",
    "d5_filtered['Dataset'] = 'Type of residence permit and citizenship'\n",
    "d5_filtered['Dataset_Code'] = 'D5'\n",
    "\n",
    "\n",
    "# print All d13 columns\n",
    "d15_filtered = d15[['CITIZENSHIP', 'Citizenship', 'Sex', 'TIME_PERIOD', 'OBS_VALUE']]\n",
    "d15_filtered = d15_filtered.rename(columns={'CITIZENSHIP': 'Country_Code',\n",
    "                                          'Citizenship': 'Country_Name',\n",
    "                                          'TIME_PERIOD': 'Year',\n",
    "                                          'OBS_VALUE': 'Value'})\n",
    "\n",
    "# Add country name to d4 and d5\n",
    "d4_filtered = d4_filtered.merge(d15_filtered[['Country_Code', 'Country_Name']], on='Country_Code', how='left')\n",
    "d5_filtered = d5_filtered.merge(d15_filtered[['Country_Code', 'Country_Name']], on='Country_Code', how='left')\n",
    "\n",
    "# Join d4 and d5\n",
    "combined = pd.concat([d4_filtered, d5_filtered], ignore_index=True)\n",
    "\n",
    "# Change Sex from integer to string\n",
    "combined['Sex'] = combined['Sex'].map(Sex_dictionary)\n",
    "\n",
    "# Change Permit_Type to improve readability\n",
    "combined['Permit_Type'] = combined['Permit_Type'].map(Permit_Type_dictionary)\n",
    "\n",
    "# Order columns: [Year, Country_Code, Country_Name, Sex, Value,  Dataset_Code, Dataset]\n",
    "combined = combined[['Year', 'Country_Code', 'Country_Name', 'Sex', 'Value','Permit_Type' , 'Dataset_Code', 'Dataset']]\n",
    "combined = combined.drop_duplicates()\n",
    "\n",
    "# order by: [Country_Code, ]\n",
    "combined = combined.sort_values(['Country_Name', 'Dataset_Code', 'Year'])\n",
    "\n",
    "# Save to CSV\n",
    "combined.to_csv(f'{datasets_path}mashup/italy_immigration_trends_by_country_and_permit.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For visualization purposes, a secondary dataset has been created in which country codes have been converted from ISO 3166-1 Alpha-3 to ISO 3166-1 Alpha-2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_iso2(code):\n",
    "    if pd.isna(code):  # Check if the value is NaN\n",
    "        return None  # Keep it as NaN\n",
    "    if code == \"GBR\":  # Manually correct \"UK\" to \"GBR\"\n",
    "        return \"GB\"\n",
    "    try:\n",
    "        return pycountry.countries.get(alpha_3=code).alpha_2\n",
    "    except AttributeError:\n",
    "        # print(f\"Warning: Country code '{code}' not found in ISO 3166-1 alpha-2!\")  # Debugging\n",
    "        return code  # Keep the original if not found\n",
    "    \n",
    "\n",
    "mashed_up = pd.read_csv(f'{datasets_path}mashup/italy_immigration_trends_by_country_and_permit.csv')\n",
    "mashed_up['Country_Code'] = mashed_up['Country_Code'].apply(convert_to_iso2)\n",
    "\n",
    "mashed_up.to_csv(f'{datasets_path}mashup/italy_immigration_trends_by_country_and_permit_iso2.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are the demographic profiles of immigrants in Italy (age, gender, educationÂ level)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "d6 = pd.read_csv(f'{datasets_path}NoiItalia2024/output_file.csv')\n",
    "d10 = pd.read_csv(f'{datasets_path}Immigrants.Stat/DCCV_TAXOCCU1_12012025110922125.csv')\n",
    "d11 = pd.read_csv(f'{datasets_path}Immigrants.Stat/DCCV_TAXDISOCCU1_12012025111208359.csv')\n",
    "d8 = pd.read_csv(f'{datasets_path}Immigrants.Stat/DCCV_OCCUPATIT1_12012025110421591.csv')\n",
    "\n",
    "d6_filtered = d6.rename(columns={'Age_Group': 'Age_class'})\n",
    "d6_filtered['Territory'] = 'Italy'\n",
    "d6_filtered['Gender'] = 'total'\n",
    "d6_filtered = d6_filtered[['Territory', 'Age_class', 'Gender', 'Education_Level', 'Year', 'Foreign_Percentage', 'Italian_Percentage']]\n",
    "\n",
    "d10_filtered = d10[['Territory', 'Age class', 'Gender', 'Highest level of education attained', 'TIME', 'Value']]\n",
    "d10_filtered = d10_filtered.rename(columns={'TIME': 'Year', 'Highest level of education attained': 'Education_Level', 'Age class': 'Age_class', 'Value': 'Employed percentage'})  \n",
    "# remove \" years\" prefix from Age_class\n",
    "d10_filtered['Age_class'] = d10_filtered['Age_class'].str.replace(' years', '')\n",
    "\n",
    "d11_filtered = d11[['Territory', 'Age class', 'Highest level of education attained', 'TIME', 'Value']]\n",
    "d11_filtered = d11_filtered.rename(columns={'TIME': 'Year', 'Highest level of education attained': 'Education_Level', 'Age class': 'Age_class', 'Value': 'Unmployed percentage'})\n",
    "d11_filtered.insert(d11_filtered.columns.get_loc('Age_class') + 1, 'Gender', 'total')\n",
    "# remove \" years\" prefix from Age_class\n",
    "d11_filtered['Age_class'] = d11_filtered['Age_class'].str.replace(' years', '')\n",
    "# Kepp the rows which Age_class is \"15-64\"\n",
    "d11_filtered = d11_filtered[d11_filtered['Age_class'] == '15-64']\n",
    "\n",
    "d8_filtered = d8[['Territory', 'Gender', 'Age class', 'Full-time/Part-time', 'TIME', 'Value']]\n",
    "d8_filtered = d8_filtered.rename(columns={'TIME': 'Year', 'Full-time/Part-time': 'Work_Type', 'Value': 'Value', 'Age class': 'Age_class'})\n",
    "# remove \" years\" prefix from Age_class\n",
    "d8_filtered['Age_class'] = d8_filtered['Age_class'].str.replace(' years', '')\n",
    "# Multiply by 1000 to get the actual number of people\n",
    "d8_filtered['Value'] = d8_filtered['Value'] * 1000\n",
    "d8_filtered[\"Education_Level\"] = 'total'\n",
    "\n",
    "# Cast all year columns to string\n",
    "d6_filtered[\"Year\"] = d6_filtered[\"Year\"].astype(str)\n",
    "d10_filtered[\"Year\"] = d10_filtered[\"Year\"].astype(str)\n",
    "d11_filtered[\"Year\"] = d11_filtered[\"Year\"].astype(str)\n",
    "d8_filtered[\"Year\"] = d8_filtered[\"Year\"].astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping dictionary for the d6_filtered dataset\n",
    "mapping_d6 = {\n",
    "    'Licenza_Media': 'no educational degree, primary and lower secondary school certificate',\n",
    "    'Diploma': 'upper and post secondary',\n",
    "    'Titolo_Universitario': 'tertiary (university, doctoral and specialization courses)'\n",
    "}\n",
    "\n",
    "# Apply the mapping to d6_filtered while preserving any values not in the mapping (like 'total')\n",
    "d6_filtered['Education_Level'] = d6_filtered['Education_Level'].apply(\n",
    "    lambda x: mapping_d6.get(x, x)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize the Year column in all datasets\n",
    "# From d8, d10, d11 remove all the querterly data and just keep the yearly data\n",
    "d8_filtered = d8_filtered[d8_filtered['Year'].str.contains('Q') == False]\n",
    "d10_filtered = d10_filtered[d10_filtered['Year'].str.contains('Q') == False]\n",
    "d11_filtered = d11_filtered[d11_filtered['Year'].str.contains('Q') == False]\n",
    "\n",
    "# In all datasets remove years before 2019\n",
    "d8_filtered = d8_filtered[d8_filtered['Year'].astype(int) >= 2019]\n",
    "d10_filtered = d10_filtered[d10_filtered['Year'].astype(int) >= 2019]\n",
    "d11_filtered = d11_filtered[d11_filtered['Year'].astype(int) >= 2019]\n",
    "d6_filtered = d6_filtered[d6_filtered['Year'].astype(int) >= 2019]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine D10 and D11\n",
    "d10_without_age = d10_filtered.drop(columns=['Age_class'])\n",
    "d10_without_age = d10_without_age.drop_duplicates()\n",
    "\n",
    "d11_without_age = d11_filtered.drop(columns=['Age_class'])\n",
    "d11_without_age = d11_without_age.drop_duplicates()\n",
    "\n",
    "d8_without_age = d8_filtered.drop(columns=['Age_class'])\n",
    "d8_without_age = d8_without_age.drop_duplicates()\n",
    "\n",
    "d10_d11 = pd.merge(d11_without_age, d10_without_age, on=['Territory', \"Education_Level\", \"Year\", \"Gender\"], how='outer')\n",
    "\n",
    "combined = pd.merge(d10_d11, d8_without_age, on=['Territory', \"Year\", \"Gender\", 'Education_Level'], how='outer')\n",
    "\n",
    "combined['Age_class'] = 'Total'\n",
    "\n",
    "# Combine with d6_filtered\n",
    "combined = pd.merge(combined, d6_filtered, on=['Territory', \"Year\", \"Gender\", 'Education_Level', \"Age_class\"], how='outer')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a custom sorting key function\n",
    "def custom_sort_key(row):\n",
    "    territory_priority = 0 if row['Territory'] == 'Italy' else 1\n",
    "    year_priority = 0 if row['Year'] == 'total' else 1\n",
    "    gender_priority = 0 if row['Gender'] == 'total' else 1\n",
    "    education_priority = 0 if row['Education_Level'] == 'total' else 1\n",
    "    work_type_priority = 0 if row['Work_Type'] == 'total' else 1\n",
    "    \n",
    "    return (territory_priority, row['Territory'], year_priority, row['Year'], gender_priority, row['Gender'], education_priority, row['Education_Level'], work_type_priority, row['Work_Type'])\n",
    "\n",
    "# Sort the dataframe using the custom sorting key\n",
    "combined['Territory_priority'] = combined['Territory'].apply(lambda x: 0 if x == 'Italy' else 1)\n",
    "combined['Year_priority'] = combined['Year'].apply(lambda x: 0 if x == 'total' else 1)\n",
    "combined['Gender_priority'] = combined['Gender'].apply(lambda x: 0 if x == 'total' else 1)\n",
    "combined['Education_Level_priority'] = combined['Education_Level'].apply(lambda x: 0 if x == 'total' else 1)\n",
    "combined['Work_Type_priority'] = combined['Work_Type'].apply(lambda x: 0 if x == 'total' else 1)\n",
    "\n",
    "combined_sorted = combined.sort_values(by=['Territory_priority', 'Territory', 'Year_priority', 'Year', 'Gender_priority', 'Gender', 'Education_Level_priority', 'Education_Level', 'Work_Type_priority', 'Work_Type'])\n",
    "\n",
    "# Drop the priority columns as they are no longer needed\n",
    "combined_sorted = combined_sorted.drop(columns=['Territory_priority', 'Year_priority', 'Gender_priority', 'Education_Level_priority', 'Work_Type_priority'])\n",
    "\n",
    "# Reset the index if needed\n",
    "combined_sorted = combined_sorted.reset_index(drop=True)\n",
    "\n",
    "combined_sorted.to_csv(f'{datasets_path}mashup/italy_employment_education_trends.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
