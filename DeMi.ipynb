{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation\n",
    "This block is for preparing libraries and modules which will be used in the project. New libraries may be added during the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the following lines to install the required packages\n",
    "# !pip install pandas\n",
    "# !pip install matplotlib\n",
    "# !pip install seaborn\n",
    "# !pip install pycountry\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pycountry\n",
    "\n",
    "datasets_path = 'datasets/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questions\n",
    "\n",
    "## What are the main countries of origin of immigrants in Italy, and how have these trends changed over the past 5 years?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate mashed-up data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_iso3(code):\n",
    "    if pd.isna(code):  # Check if the value is NaN\n",
    "        return None  # Keep it as NaN\n",
    "    if code == \"UK\":  # Manually correct \"UK\" to \"GBR\"\n",
    "        return \"GBR\"\n",
    "    try:\n",
    "        return pycountry.countries.get(alpha_2=code).alpha_3\n",
    "    except AttributeError:\n",
    "        # print(f\"Warning: Country code '{code}' not found in ISO 3166-1 alpha-2!\")  # Debugging\n",
    "        return code  # Keep the original if not found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load datasets\n",
    "d4 = pd.read_csv(f'{datasets_path}IstatData/Immigrants - citizenship (IT1,28_185_DF_DCIS_MIGRAZIONI_2,1.0).csv')\n",
    "d5 = pd.read_csv(f'{datasets_path}IstatData/Type of residence permit and citizenship (IT1,29_348_DF_DCIS_PERMSOGG1_1,1.0).csv')\n",
    "d15 = pd.read_csv(f'{datasets_path}OECD/OECD.ELS.IMD,DSD_MIG@DF_MIG,1.0+ITA..A.B11.csv')\n",
    "\n",
    "Sex_dictionary = {\n",
    "  1: \"Male\",\n",
    "  2: \"Female\",\n",
    "  9: \"Total\",\n",
    "}\n",
    "\n",
    "Permit_Type_dictionary = {\n",
    "  \"LONGT\": \"Long-term\",\n",
    "  \"NLONGT\": \"Short-term\",\n",
    "  \"TOTAL\": \"Total\",\n",
    "}\n",
    "\n",
    "d4_filtered = d4[d4['AGE'] == 'TOTAL'][['CITIZENSHIP',\n",
    "                                        'SEX',\n",
    "                                        # 'AGE',\n",
    "                                        'TIME_PERIOD',\n",
    "                                        'OBS_VALUE']]\n",
    "d4_filtered = d4_filtered.rename(columns={'CITIZENSHIP': 'Country_Code',\n",
    "                                          'SEX': 'Sex',\n",
    "                                        #   'AGE': 'Age_range',\n",
    "                                          'TIME_PERIOD': 'Year',\n",
    "                                          'OBS_VALUE': 'Value'})\n",
    "d4_filtered = d4_filtered[d4_filtered['Country_Code'].str.len() == 2]\n",
    "# Convert country codes to ISO 3166-1 alpha-3\n",
    "d4_filtered['Country_Code'] = d4_filtered['Country_Code'].apply(convert_to_iso3)\n",
    "# Add column dataset = d4\n",
    "d4_filtered['Dataset'] = 'Immigrants - citizenship'\n",
    "d4_filtered['Dataset_Code'] = 'D4'\n",
    "\n",
    "\n",
    "d5_filtered = d5[['MOSTREL_CCITENSHIP',\n",
    "                  'SEX', 'TYPE_RES_PERMIT',\n",
    "                  'TIME_PERIOD',\n",
    "                  'OBS_VALUE']]\n",
    "d5_filtered = d5_filtered.rename(columns={'MOSTREL_CCITENSHIP': 'Country_Code',\n",
    "                                          'SEX': 'Sex',\n",
    "                                          'TYPE_RES_PERMIT': 'Permit_Type',\n",
    "                                          'TIME_PERIOD': 'Year',\n",
    "                                          'OBS_VALUE': 'Value'})\n",
    "d5_filtered = d5_filtered[d5_filtered['Country_Code'].str.len() == 2]\n",
    "# Convert country codes to ISO 3166-1 alpha-3\n",
    "d5_filtered['Country_Code'] = d5_filtered['Country_Code'].apply(convert_to_iso3)\n",
    "# Add column dataset = d5\n",
    "d5_filtered['Dataset'] = 'Type of residence permit and citizenship'\n",
    "d5_filtered['Dataset_Code'] = 'D5'\n",
    "\n",
    "\n",
    "# print All d13 columns\n",
    "d15_filtered = d15[['CITIZENSHIP', 'Citizenship', 'Sex', 'TIME_PERIOD', 'OBS_VALUE']]\n",
    "d15_filtered = d15_filtered.rename(columns={'CITIZENSHIP': 'Country_Code',\n",
    "                                          'Citizenship': 'Country_Name',\n",
    "                                          'TIME_PERIOD': 'Year',\n",
    "                                          'OBS_VALUE': 'Value'})\n",
    "\n",
    "# Add country name to d4 and d5\n",
    "d4_filtered = d4_filtered.merge(d15_filtered[['Country_Code', 'Country_Name']], on='Country_Code', how='left')\n",
    "d5_filtered = d5_filtered.merge(d15_filtered[['Country_Code', 'Country_Name']], on='Country_Code', how='left')\n",
    "\n",
    "# Join d4 and d5\n",
    "combined = pd.concat([d4_filtered, d5_filtered], ignore_index=True)\n",
    "\n",
    "# Change Sex from integer to string\n",
    "combined['Sex'] = combined['Sex'].map(Sex_dictionary)\n",
    "\n",
    "# Change Permit_Type to improve readability\n",
    "combined['Permit_Type'] = combined['Permit_Type'].map(Permit_Type_dictionary)\n",
    "\n",
    "# Order columns: [Year, Country_Code, Country_Name, Sex, Value,  Dataset_Code, Dataset]\n",
    "combined = combined[['Year', 'Country_Code', 'Country_Name', 'Sex', 'Value','Permit_Type' , 'Dataset_Code', 'Dataset']]\n",
    "combined = combined.drop_duplicates()\n",
    "\n",
    "# order by: [Country_Code, ]\n",
    "combined = combined.sort_values(['Country_Name', 'Dataset_Code', 'Year'])\n",
    "\n",
    "# Save to CSV\n",
    "combined.to_csv(f'{datasets_path}mashup/italy_immigration_trends_by_country_and_permit.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For visualization purposes, a secondary dataset has been created in which country codes have been converted from ISO 3166-1 Alpha-3 to ISO 3166-1 Alpha-2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_iso2(code):\n",
    "    if pd.isna(code):  # Check if the value is NaN\n",
    "        return None  # Keep it as NaN\n",
    "    if code == \"GBR\":  # Manually correct \"UK\" to \"GBR\"\n",
    "        return \"GB\"\n",
    "    try:\n",
    "        return pycountry.countries.get(alpha_3=code).alpha_2\n",
    "    except AttributeError:\n",
    "        # print(f\"Warning: Country code '{code}' not found in ISO 3166-1 alpha-2!\")  # Debugging\n",
    "        return code  # Keep the original if not found\n",
    "    \n",
    "\n",
    "mashed_up = pd.read_csv(f'{datasets_path}mashup/italy_immigration_trends_by_country_and_permit.csv')\n",
    "mashed_up['Country_Code'] = mashed_up['Country_Code'].apply(convert_to_iso2)\n",
    "\n",
    "mashed_up.to_csv(f'{datasets_path}mashup/italy_immigration_trends_by_country_and_permit_iso2.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are the demographic profiles of immigrants in Italy (age, gender, educationÂ level)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "d6 = pd.read_csv(f'{datasets_path}NoiItalia2024/output_file.csv')\n",
    "d10 = pd.read_csv(f'{datasets_path}Immigrants.Stat/DCCV_TAXOCCU1_12012025110922125.csv')\n",
    "d11 = pd.read_csv(f'{datasets_path}Immigrants.Stat/DCCV_TAXDISOCCU1_12012025111208359.csv')\n",
    "d8 = pd.read_csv(f'{datasets_path}Immigrants.Stat/DCCV_OCCUPATIT1_12012025110421591.csv')\n",
    "\n",
    "d6_filtered = d6.rename(columns={'Age_Group': 'Age_class'})\n",
    "d6_filtered['Territory'] = 'Italy'\n",
    "d6_filtered['Gender'] = 'total'\n",
    "d6_filtered = d6_filtered[['Territory', 'Age_class', 'Gender', 'Education_Level', 'Year', 'Foreign_Percentage', 'Italian_Percentage']]\n",
    "\n",
    "d10_filtered = d10[['Territory', 'Age class', 'Gender', 'Highest level of education attained', 'TIME', 'Value']]\n",
    "d10_filtered = d10_filtered.rename(columns={'TIME': 'Year', 'Highest level of education attained': 'Education_Level', 'Age class': 'Age_class', 'Value': 'Employed_percentage'})  \n",
    "# remove \" years\" prefix from Age_class\n",
    "d10_filtered['Age_class'] = d10_filtered['Age_class'].str.replace(' years', '')\n",
    "\n",
    "d11_filtered = d11[['Territory', 'Age class', 'Highest level of education attained', 'TIME', 'Value']]\n",
    "d11_filtered = d11_filtered.rename(columns={'TIME': 'Year', 'Highest level of education attained': 'Education_Level', 'Age class': 'Age_class', 'Value': 'Unemployed_percentage'})\n",
    "d11_filtered.insert(d11_filtered.columns.get_loc('Age_class') + 1, 'Gender', 'total')\n",
    "# remove \" years\" prefix from Age_class\n",
    "d11_filtered['Age_class'] = d11_filtered['Age_class'].str.replace(' years', '')\n",
    "# Kepp the rows which Age_class is \"15-64\"\n",
    "d11_filtered = d11_filtered[d11_filtered['Age_class'] == '15-64']\n",
    "\n",
    "d8_filtered = d8[['Territory', 'Gender', 'Age class', 'Full-time/Part-time', 'TIME', 'Value']]\n",
    "d8_filtered = d8_filtered.rename(columns={'TIME': 'Year', 'Full-time/Part-time': 'Work_Type', 'Value': 'Value', 'Age class': 'Age_class'})\n",
    "# remove \" years\" prefix from Age_class\n",
    "d8_filtered['Age_class'] = d8_filtered['Age_class'].str.replace(' years', '')\n",
    "# Multiply by 1000 to get the actual number of people\n",
    "d8_filtered['Value'] = d8_filtered['Value'] * 1000\n",
    "d8_filtered[\"Education_Level\"] = 'total'\n",
    "\n",
    "# Cast all year columns to string\n",
    "d6_filtered[\"Year\"] = d6_filtered[\"Year\"].astype(str)\n",
    "d10_filtered[\"Year\"] = d10_filtered[\"Year\"].astype(str)\n",
    "d11_filtered[\"Year\"] = d11_filtered[\"Year\"].astype(str)\n",
    "d8_filtered[\"Year\"] = d8_filtered[\"Year\"].astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping dictionary for the d6_filtered dataset\n",
    "mapping_d6 = {\n",
    "    'Licenza_Media': 'no educational degree, primary and lower secondary school certificate',\n",
    "    'Diploma': 'upper and post secondary',\n",
    "    'Titolo_Universitario': 'tertiary (university, doctoral and specialization courses)'\n",
    "}\n",
    "\n",
    "# Apply the mapping to d6_filtered while preserving any values not in the mapping (like 'total')\n",
    "d6_filtered['Education_Level'] = d6_filtered['Education_Level'].apply(\n",
    "    lambda x: mapping_d6.get(x, x)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize the Year column in all datasets\n",
    "# From d8, d10, d11 remove all the querterly data and just keep the yearly data\n",
    "d8_filtered = d8_filtered[d8_filtered['Year'].str.contains('Q') == False]\n",
    "d10_filtered = d10_filtered[d10_filtered['Year'].str.contains('Q') == False]\n",
    "d11_filtered = d11_filtered[d11_filtered['Year'].str.contains('Q') == False]\n",
    "\n",
    "# In all datasets remove years before 2019\n",
    "d8_filtered = d8_filtered[d8_filtered['Year'].astype(int) >= 2019]\n",
    "d10_filtered = d10_filtered[d10_filtered['Year'].astype(int) >= 2019]\n",
    "d11_filtered = d11_filtered[d11_filtered['Year'].astype(int) >= 2019]\n",
    "d6_filtered = d6_filtered[d6_filtered['Year'].astype(int) >= 2019]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine D10 and D11\n",
    "d10_without_age = d10_filtered.drop(columns=['Age_class'])\n",
    "d10_without_age = d10_without_age.drop_duplicates()\n",
    "\n",
    "d11_without_age = d11_filtered.drop(columns=['Age_class'])\n",
    "d11_without_age = d11_without_age.drop_duplicates()\n",
    "\n",
    "d8_without_age = d8_filtered.drop(columns=['Age_class'])\n",
    "d8_without_age = d8_without_age.drop_duplicates()\n",
    "\n",
    "d10_d11 = pd.merge(d11_without_age, d10_without_age, on=['Territory', \"Education_Level\", \"Year\", \"Gender\"], how='outer')\n",
    "\n",
    "combined = pd.merge(d10_d11, d8_without_age, on=['Territory', \"Year\", \"Gender\", 'Education_Level'], how='outer')\n",
    "\n",
    "combined['Age_class'] = 'Total'\n",
    "\n",
    "# Combine with d6_filtered\n",
    "combined = pd.merge(combined, d6_filtered, on=['Territory', \"Year\", \"Gender\", 'Education_Level', \"Age_class\"], how='outer')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'datasets/mashup/italy_employment_education_trends.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 26\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Reset the index if needed\u001b[39;00m\n\u001b[0;32m     24\u001b[0m combined_sorted \u001b[38;5;241m=\u001b[39m combined_sorted\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m---> 26\u001b[0m \u001b[43mcombined_sorted\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mdatasets_path\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43mmashup/italy_employment_education_trends.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32me:\\Workspace\\DeMi\\.venv\\Lib\\site-packages\\pandas\\util\\_decorators.py:333\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    328\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    329\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    330\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    331\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    332\u001b[0m     )\n\u001b[1;32m--> 333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32me:\\Workspace\\DeMi\\.venv\\Lib\\site-packages\\pandas\\core\\generic.py:3967\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[0;32m   3956\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_frame()\n\u001b[0;32m   3958\u001b[0m formatter \u001b[38;5;241m=\u001b[39m DataFrameFormatter(\n\u001b[0;32m   3959\u001b[0m     frame\u001b[38;5;241m=\u001b[39mdf,\n\u001b[0;32m   3960\u001b[0m     header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3964\u001b[0m     decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[0;32m   3965\u001b[0m )\n\u001b[1;32m-> 3967\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameRenderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3968\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3969\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlineterminator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3970\u001b[0m \u001b[43m    \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3971\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3972\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3973\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3974\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquoting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3975\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3976\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3977\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3978\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3979\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquotechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquotechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3980\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3981\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdoublequote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3982\u001b[0m \u001b[43m    \u001b[49m\u001b[43mescapechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mescapechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3983\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3984\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32me:\\Workspace\\DeMi\\.venv\\Lib\\site-packages\\pandas\\io\\formats\\format.py:1014\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[0;32m    993\u001b[0m     created_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    995\u001b[0m csv_formatter \u001b[38;5;241m=\u001b[39m CSVFormatter(\n\u001b[0;32m    996\u001b[0m     path_or_buf\u001b[38;5;241m=\u001b[39mpath_or_buf,\n\u001b[0;32m    997\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1012\u001b[0m     formatter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt,\n\u001b[0;32m   1013\u001b[0m )\n\u001b[1;32m-> 1014\u001b[0m \u001b[43mcsv_formatter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1016\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[0;32m   1017\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[1;32me:\\Workspace\\DeMi\\.venv\\Lib\\site-packages\\pandas\\io\\formats\\csvs.py:251\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    247\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;124;03mCreate the writer & save.\u001b[39;00m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;66;03m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[1;32m--> 251\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    258\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter \u001b[38;5;241m=\u001b[39m csvlib\u001b[38;5;241m.\u001b[39mwriter(\n\u001b[0;32m    261\u001b[0m         handles\u001b[38;5;241m.\u001b[39mhandle,\n\u001b[0;32m    262\u001b[0m         lineterminator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    267\u001b[0m         quotechar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquotechar,\n\u001b[0;32m    268\u001b[0m     )\n\u001b[0;32m    270\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save()\n",
      "File \u001b[1;32me:\\Workspace\\DeMi\\.venv\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'datasets/mashup/italy_employment_education_trends.csv'"
     ]
    }
   ],
   "source": [
    "# Define a custom sorting key function\n",
    "def custom_sort_key(row):\n",
    "    territory_priority = 0 if row['Territory'] == 'Italy' else 1\n",
    "    year_priority = 0 if row['Year'] == 'total' else 1\n",
    "    gender_priority = 0 if row['Gender'] == 'total' else 1\n",
    "    education_priority = 0 if row['Education_Level'] == 'total' else 1\n",
    "    work_type_priority = 0 if row['Work_Type'] == 'total' else 1\n",
    "    \n",
    "    return (territory_priority, row['Territory'], year_priority, row['Year'], gender_priority, row['Gender'], education_priority, row['Education_Level'], work_type_priority, row['Work_Type'])\n",
    "\n",
    "# Sort the dataframe using the custom sorting key\n",
    "combined['Territory_priority'] = combined['Territory'].apply(lambda x: 0 if x == 'Italy' else 1)\n",
    "combined['Year_priority'] = combined['Year'].apply(lambda x: 0 if x == 'total' else 1)\n",
    "combined['Gender_priority'] = combined['Gender'].apply(lambda x: 0 if x == 'total' else 1)\n",
    "combined['Education_Level_priority'] = combined['Education_Level'].apply(lambda x: 0 if x == 'total' else 1)\n",
    "combined['Work_Type_priority'] = combined['Work_Type'].apply(lambda x: 0 if x == 'total' else 1)\n",
    "\n",
    "combined_sorted = combined.sort_values(by=['Territory_priority', 'Territory', 'Year_priority', 'Year', 'Gender_priority', 'Gender', 'Education_Level_priority', 'Education_Level', 'Work_Type_priority', 'Work_Type'])\n",
    "\n",
    "# Drop the priority columns as they are no longer needed\n",
    "combined_sorted = combined_sorted.drop(columns=['Territory_priority', 'Year_priority', 'Gender_priority', 'Education_Level_priority', 'Work_Type_priority'])\n",
    "\n",
    "# Reset the index if needed\n",
    "combined_sorted = combined_sorted.reset_index(drop=True)\n",
    "\n",
    "combined_sorted.to_csv(f'{datasets_path}mashup/italy_employment_education_trends.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
